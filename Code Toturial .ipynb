{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bdfa1ff-8d71-48db-8df4-c19a37b6308a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d667f3b6-502f-45ae-92fc-6ff8c4509a0d",
   "metadata": {},
   "source": [
    "# **Concrete Compressive Strength Prediction Using a Neural Network**\n",
    "\n",
    "**In this tutorial**, we will predict the compressive strength of concrete using a neural network model. The dataset is sourced from the UCI Machine Learning Repository, and the `ucimlrepo` library will be used to fetch the dataset. We will preprocess the data, build and train a neural network, and evaluate its performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Install Necessary Libraries**\n",
    "\n",
    "Before proceeding, make sure to install the required libraries. This step is only needed if you're running the notebook on Google Colab or any environment where these libraries are not pre-installed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147e220-ec0b-414c-8684-4792ac42a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries for Google Colab\n",
    "!pip install ucimlrepo tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367c5227-d753-494f-8ba8-6eb71b29d13e",
   "metadata": {},
   "source": [
    "## **Step 2: Import Required Libraries**\r\n",
    "\r\n",
    "We begin by importing the necessary libraries for data handling, model building, and evaluation. These include:\r\n",
    "\r\n",
    "- **pandas**: for data manipulation.\r\n",
    "- **fetch_ucirepo**: from the `ucimlrepo` library to fetch the dataset.\r\n",
    "- **train_test_split**: from `sklearn.model_selection` for splitting the data.\r\n",
    "- **mean_squared_error**: from `sklearn.metrics` to evaluate the model's performance.\r\n",
    "- **keras**: from TensorFlow to build the neural network.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ae960d-9f0e-415d-8c5c-a684c9080791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252264cf-42f3-4179-abd1-7e41cc76583b",
   "metadata": {},
   "source": [
    "## **Step 3: Fetch the Dataset**\r\n",
    "\r\n",
    "We use the `fetch_ucirepo` function to retrieve the Concrete Compressive Strength dataset from the UCI repository. This dataset contains data on various components of concrete and their corresponding compressive strength.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6be5a2-3a8a-42c9-810f-8dffac5882a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch dataset\n",
    "concrete_compressive_strength = fetch_ucirepo(id=165)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d56e84-a5d6-4628-b3ba-00a2646e0ce6",
   "metadata": {},
   "source": [
    "## **Step 4: Prepare the Data**\r\n",
    "\r\n",
    "We convert the dataset into a pandas DataFrame. The features (**X**) represent the input data, while the target variable (**y**) represents the compressive strength of concrete that we want to predict.\r\n",
    "\r\n",
    "We flatten the target variable to ensure it's in the correct format for regression. \r\n",
    "\r\n",
    "Finally, we display the shape of the dataset to understand the dimensionality.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b8fbf-343d-419f-868e-f7fb5f1eaae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data as pandas DataFrame\n",
    "X = concrete_compressive_strength.data.features\n",
    "y = concrete_compressive_strength.data.targets.values.flatten()  # Flatten the target variable\n",
    "\n",
    "# Display the original data shape\n",
    "print(\"Original data shape:\")\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ee0b9d-5bde-4758-afa4-51d36b6905ae",
   "metadata": {},
   "source": [
    "## **Step 5: Split the Data**\r\n",
    "\r\n",
    "We split the dataset into training and testing sets using an 80/20 split. This allows us to train the model on 80% of the data and evaluate it on the remaining 20%.\r\n",
    "\r\n",
    "- **X_train** and **y_train**: represent the training set.\r\n",
    "- **X_test** and **y_test**: represent the testing set.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab63de7-fa7b-4414-831f-b5077149c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"\\nTraining set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a21ea1-55e8-42f5-a0d4-f311425e3ae2",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "## **Step 6: Build the Neural Network**\r\n",
    "\r\n",
    "We construct a neural network model with two hidden layers:\r\n",
    "- The first layer has 64 neurons and uses the ReLU activation function.\r\n",
    "- The second layer has 32 neurons, also using the ReLU activation function.\r\n",
    "- The output layer has 1 neuron since this is a regression problem where we want to predict a single continuous value (compressive strength).\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee060fa5-86c7-41ec-bbd7-c664455a9bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the neural network model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)  # Output layer for regression\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86422eec-11d1-4387-bfaf-aedef6b558d7",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "## **Step 7: Compile the Model**\r\n",
    "\r\n",
    "We compile the model with:\r\n",
    "- **Optimizer:** Adam, a popular optimization algorithm for neural networks.\r\n",
    "- **Loss function:** Mean Squared Error (MSE), suitable for regression problems where we measure the average squared difference between actual and predicted values.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30805fa9-88b4-47aa-81ed-a629fde7c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb73aa-bece-4e15-bbf7-71bf166e9416",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "## **Step 8: Train the Model**\r\n",
    "\r\n",
    "We train the neural network using the training set (`X_train`, `y_train`). During training:\r\n",
    "- The model runs for 100 epochs.\r\n",
    "- A batch size of 32 is used, meaning the model processes 32 samples at a time.\r\n",
    "- We use a validation split of 20%, so the model evaluates performance on 20% of the training data during training.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d964bf3-438f-4882-8581-31b76db54aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2af17c9-269d-472e-997c-01ea81d46cef",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "## **Step 9: Make Predictions**\r\n",
    "\r\n",
    "After the model is trained, we make predictions on the test set (`X_test`). These predictions represent the model's estimate of the compressive strength based on unseen data.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01edbab-5590-4d32-abb4-2ad604d7ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1446c1c6-0cb1-4bcd-a870-1b1b54194e36",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "## **Step 10: Evaluate the Model**\r\n",
    "\r\n",
    "We evaluate the model's performance by calculating the Mean Squared Error (MSE) on the test set. A lower MSE indicates better model performance.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed3937-a1fe-4d55-a691-57bb5a412654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"\\nMean Squared Error on the test set:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891443ff-71c1-437a-b774-792af144f109",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "## **Step 11: View Sample Predictions**\r\n",
    "\r\n",
    "We display a few sample predictions alongside their actual values for comparison. This helps us understand how well the model is performing at a glance.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5d636b-772b-44a6-a806-11b4fd747104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few predictions\n",
    "predictions_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred.flatten()})\n",
    "print(\"\\nSample predictions:\")\n",
    "print(predictions_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
